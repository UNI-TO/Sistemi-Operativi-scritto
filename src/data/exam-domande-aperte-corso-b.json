{
  "id": "domande-aperte-corso-b",
  "date": "2024.00.00",
  "course": "B",
  "title": "Domande Aperte Corso B - Teoria SO (13 Domande Essay)",
  "topics": [
    "generalita",
    "processi-scheduling",
    "sincronizzazione",
    "memoria-primaria",
    "file-system"
  ],
  "questions": [
    {
      "number": 1,
      "text": "I \"grafi di allocazione delle risorse\" sono strumenti di rilevazione o di prevenzione del deadlock? In quale modo possono essere usati a questo scopo? Vi sono eventuali vincoli?",
      "answer": "I grafi di allocazione delle risorse sono strumenti di rilevazione del deadlock.\n\nI grafi permettono di rappresentare graficamente le assegnazioni delle risorse ai processi. Se il grafo non contiene cicli, non c'è deadlock. Se il grafo contiene un ciclo con risorse aventi tutte una sola istanza, c'è deadlock. Se il ciclo comprende risorse con più istanze, il ciclo è condizione necessaria ma non sufficiente.\n\nL'uso dei grafi come strumento di rilevazione non prevede vincoli particolari.",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "sincronizzazione",
        "deadlock"
      ]
    },
    {
      "number": 2,
      "text": "(1) Si spieghi per quale motivo i metodi di allocazione della RAM per i processi kernel devono essere diversi da quelli per i processi utente e (2) si illustri il metodo di allocazione noto come sistema buddy.",
      "answer": "(1) I metodi di allocazione RAM per i processi kernel devono essere diversi per due motivi principali:\n- Strutture dati variabili: I processi kernel gestiscono strutture dati che cambiano dimensione (liste, code)\n- Memoria contigua: Alcuni processi kernel, specialmente quelli che lavorano con l'hardware, necessitano di memoria contigua per operazioni I/O\n\n(2) Il sistema buddy:\n- Suddivide la memoria in blocchi di dimensione pari a potenze di 2\n- Cerca il blocco più piccolo sufficiente per la richiesta\n- Se il blocco è troppo grande, lo divide in due blocchi \"buddy\" di dimensione pari alla metà\n- Quando un blocco viene liberato, verifica se il suo \"buddy\" è libero e li fonde insieme\n- Vantaggi: semplice da implementare, riduce frammentazione esterna\n- Svantaggi: può causare frammentazione interna significativa",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "memoria-primaria",
        "kernel"
      ]
    },
    {
      "number": 3,
      "text": "(1) Spiegare il dual mode e cosa si intende per system call, (2) dire cos'è e come viene usato il vettore delle interruzioni.",
      "answer": "(1) Dual mode e system call:\nIl dual mode prevede la divisione dell'instruction set in:\n- Istruzioni privilegiate (eseguibili solo dal SO in modalità kernel)\n- Istruzioni non privilegiate (eseguibili in modalità utente)\nSi basa su un bit di modalità (0=kernel, 1=utente).\n\nLe system call sono meccanismi che permettono ai processi utente di richiedere al SO di eseguire operazioni privilegiate. Durante una system call: il processo invia una trap, il SO passa in modalità kernel, esegue l'operazione, ritorna in modalità utente.\n\n(2) Vettore delle interruzioni:\nÈ una tabella contenente gli indirizzi degli handler degli interrupt. Quando si verifica un'interruzione:\n- L'hardware genera un segnale con l'ID dell'interruzione\n- La CPU usa l'ID come indice nel vettore per ottenere l'indirizzo dell'handler\n- Salva lo stato corrente ed esegue l'handler",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "generalita",
        "system-call",
        "interruzioni"
      ]
    },
    {
      "number": 4,
      "text": "(1) Spiegare cosa si intende per parallelismo virtuale, compresi quali fondamenti rendano possibile tale meccanismo. (2) Cos'è e come viene gestito dal SO un context switch.",
      "answer": "(1) Parallelismo virtuale:\nÈ un meccanismo che consente di eseguire più processi \"contemporaneamente\" su un singolo processore, dando l'illusione di esecuzione parallela. Il processore esegue solo un processo alla volta, ma la commutazione è così rapida da creare l'impressione di simultaneità.\n\nFondamenti che lo rendono possibile:\n- Multiprogrammazione: gestione di più processi contemporaneamente\n- Scheduling della CPU: algoritmo per decidere quale processo eseguire\n- Interruzioni: segnali per interrompere l'esecuzione e passare ad altro processo\n- Context Switch: meccanismo per salvare/caricare stato processi\n\n(2) Context switch:\nÈ il processo di salvataggio dello stato di un processo in esecuzione e caricamento dello stato di un altro processo. È gestito dal SO ed è un'operazione costosa. Si verifica durante interruzioni hardware o system call.",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "processi-scheduling",
        "context-switch"
      ]
    },
    {
      "number": 5,
      "text": "(1) Si spieghi che cos'è e a che cosa serve una tabella delle pagine. (2) Si spieghi perché il suo mantenimento in RAM rallenta l'esecuzione.",
      "answer": "(1) Tabella delle pagine:\nÈ una struttura dati per gestire la memoria virtuale, che funge da mappa per tradurre indirizzi logici in indirizzi fisici. Ogni processo ha la propria tabella memorizzata in RAM, contenente una entry per ogni pagina. Ogni entry contiene:\n- Numero di frame corrispondente\n- Bit di validità\n- Dirty bit\n- Bit di protezione\n\nConsente di: mappare indirizzi logici su fisici, implementare demand paging, proteggere la memoria, condividere pagine tra processi.\n\n(2) Rallentamento esecuzione:\nMantenere la tabella in RAM rallenta perché per ogni accesso alla memoria servono DUE accessi alla RAM:\n1. Accesso alla tabella delle pagine per trovare l'entry\n2. Accesso all'indirizzo fisico ottenuto\n\nPer mitigare il problema si usa il TLB (Translation Look-aside Buffer), una cache che memorizza le traduzioni più recenti.",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "memoria-primaria",
        "paginazione",
        "TLB"
      ]
    },
    {
      "number": 6,
      "text": "(1) Si spieghi cos'è test-and-set e (2) si spieghi come controllare una sezione critica tramite test-and-set.",
      "answer": "(1) Test-and-set:\nÈ un'istruzione atomica fornita dall'hardware per la sincronizzazione dei processi. Prende come parametro un puntatore ad una variabile booleana e svolge atomicamente:\n1. Salva il valore originale della variabile\n2. Imposta la variabile a true\n3. Restituisce il valore originale\n\n(2) Controllo sezione critica:\nSi usa una variabile booleana globale \"lock\" inizializzata a false.\n\nCodice:\nwhile (TestAndSet(&lock)); // Sezione di ingresso\n<sezione critica>\nlock = false;             // Sezione di uscita\n\nSe lock è true, un altro processo è nella sezione critica, quindi si aspetta nel while. Quando lock diventa false, il processo entra e imposta lock a true. L'atomicità garantisce che solo un processo alla volta ottenga il lock.",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "sincronizzazione",
        "sezione-critica",
        "test-and-set"
      ]
    },
    {
      "number": 7,
      "text": "(1) Si spieghi che cos'è una system call (2) si spieghi cosa permettono di fare e si faccia un esempio di system call",
      "answer": "(1) System call:\nÈ un meccanismo che consente ai processi in modalità utente di richiedere servizi al sistema operativo che opera in modalità kernel. È un'interfaccia tra programmi utente e SO per eseguire operazioni che richiedono privilegi speciali.\n\n(2) Cosa permettono di fare:\n- Controllo dei Processi: creare, terminare, sospendere processi\n- Gestione dei File: creare, aprire, leggere, scrivere, cancellare file\n- Gestione dei Dispositivi: richiedere/rilasciare dispositivi, leggere/scrivere\n- Gestione delle Informazioni: ottenere info sul sistema\n- Comunicazione: inviare/ricevere messaggi tra processi\n\nEsempio: open() in Unix apre un file e restituisce un file descriptor che può essere usato da altre system call come read() e write().",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "generalita",
        "system-call"
      ]
    },
    {
      "number": 8,
      "text": "1) Spiegare in cosa consiste il problema della sezione critica. 2) Elencare e definire le tre proprietà di una buona soluzione al problema della sezione critica",
      "answer": "1) Problema della sezione critica:\nRiguarda la gestione di dati condivisi in un sistema concorrente. Una sezione critica è una porzione di codice in cui un processo modifica variabili condivise. Solo un processo alla volta può essere nella sua sezione critica (mutua esclusione), altrimenti si verificano inconsistenze.\n\n2) Tre proprietà di una buona soluzione:\n- Mutua esclusione: Solo un processo alla volta può eseguire la propria sezione critica\n- Progresso: Nessun processo che non sia interessato alla sezione critica può bloccare altri processi dall'accedervi. Solo i processi interessati concorrono a determinare chi entrerà\n- Attesa limitata: Esiste un limite superiore al tempo di attesa per un processo che desidera entrare in sezione critica",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "sincronizzazione",
        "sezione-critica"
      ]
    },
    {
      "number": 9,
      "text": "(1) Spiegare cos'è il vettore delle interruzione e come viene usato per gestire gli eventi. (2) Spiegare in quali circostanze occorre un page fault",
      "answer": "(1) Vettore delle interruzioni:\nÈ un array di puntatori a funzioni di gestione eventi. Ogni evento ha un ID univoco corrispondente all'indice del vettore. Funzionamento:\n- Dispositivo/programma genera interruzione\n- CPU salva stato e identifica ID interruzione\n- ID usato come indice nel vettore per trovare routine di gestione\n- CPU esegue routine di gestione\n- Ripristina stato e riprende esecuzione\n\n(2) Page fault:\nSi verifica quando un processo cerca di accedere ad una pagina di memoria virtuale non presente in RAM. Circostanze:\n- Pagina non caricata: mai stata caricata in RAM\n- Pagina in memoria secondaria: caricata in precedenza ma sostituita\n- Accesso non valido: accesso a pagina non assegnata o senza permessi\n\nIl SO interrompe il processo e gestisce il page fault caricando la pagina richiesta. Se non c'è spazio, trova una pagina vittima da spostare in memoria secondaria (algoritmi: Second Chance, LRU).",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "generalita",
        "interruzioni",
        "memoria-primaria",
        "page-fault"
      ]
    },
    {
      "number": 10,
      "text": "(1) Spiegare cosa sono e dove sono memorizzati gli INODE e (2) spiegare l'allocazione concatenata dei blocchi ai file.",
      "answer": "(1) INODE (Index Node o FCB):\nSono strutture dati fondamentali nei file system che memorizzano i metadati di un file (eccetto nome e dati). Contenuto tipico:\n- User ID proprietario\n- Tipo file (regolare, directory, link, device)\n- Diritti di accesso\n- Tempi di accesso/modifica\n- Numero di link\n- Dimensione file\n- Puntatori ai blocchi dati\n\nQuando un file è aperto, il suo FCB viene aggiunto alla lista dei file aperti. Se in uso da un processo, l'INODE viene caricato in RAM come \"in-core inode\". Si usa l'algoritmo namei per risalire all'INODE tramite path.\n\n(2) Allocazione concatenata:\nI file sono allocati in blocchi collegati come catena. Ogni blocco contiene dati e puntatore al blocco successivo. L'INODE contiene puntatore al primo blocco.\n\nVantaggi: blocchi non contigui, aggiunta blocchi rapida, niente frammentazione esterna\nSvantaggi: lettura lenta (scorrere tutta catena), puntatore danneggiato rende file illeggibile",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "file-system",
        "INODE",
        "allocazione-file"
      ]
    },
    {
      "number": 11,
      "text": "(1) Elencare e definire le tre proprietà di una buona soluzione al problema della sezione critica; (2) Con riferimento al seguente codice (dove S è un semaforo inizializzato a 2) dire e spiegare se soddisfa tali proprietà: P(S) ... Sezione Critica ... V(S)",
      "answer": "(1) Tre proprietà:\n- Mutua Esclusione: Solo un processo alla volta può accedere alla sezione critica\n- Progresso: Se nessun processo è nella sezione critica, un processo che desidera entrarvi deve poterlo fare senza blocco indefinito\n- Attesa Limitata: Esiste un limite massimo al tempo di attesa prima di accedere alla sezione critica\n\n(2) Analisi codice con S=2:\nAssunzioni: P(S) e V(S) sono atomiche e implementate correttamente.\n\nSoddisfazione proprietà:\n- Mutua Esclusione: NON soddisfatta. S=2 significa che DUE processi possono entrare contemporaneamente nella sezione critica. Per mutua esclusione serve S=1.\n- Progresso: Soddisfatta. Se nessun processo è nella sezione critica (S=2), un processo che esegue P(S) può accedere.\n- Attesa Limitata: Soddisfatta. L'attesa è limitata dal numero di processi che possono accedere (2 in questo caso).",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "sincronizzazione",
        "sezione-critica",
        "semafori"
      ]
    },
    {
      "number": 12,
      "text": "(1) Spiegare cosa si intende per \"interleaving delle istruzioni\". (2) Spiegare come tale meccanismo supporta la realizzazione del multi-tasking",
      "answer": "(1) Interleaving delle istruzioni:\nÈ l'interfogliamento delle istruzioni, ovvero la capacità del SO di eseguire in modo interleaved le istruzioni di diversi processi, creando l'illusione di esecuzione contemporanea. Su un singolo processore solo un'istruzione alla volta può essere eseguita, ma il SO sospende/riprende processi molto rapidamente.\n\n(2) Supporto al multi-tasking:\nL'interleaving è un meccanismo chiave per il multi-tasking:\n- Il SO può sospendere un processo e passare a un altro molto rapidamente\n- Usa il context switch per salvare lo stato del processo corrente e caricare quello di un altro\n- Crea l'impressione di esecuzione parallela dei processi\n- Migliora l'efficienza complessiva del sistema\n- Consente gestione concorrente di più processi",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "processi-scheduling",
        "multi-tasking",
        "interleaving"
      ]
    },
    {
      "number": 13,
      "text": "(1) Si spieghi l'allocazione della RAM a partizioni contigue e (2) se ne spieghino vantaggi e svantaggi",
      "answer": "(1) Allocazione contigua RAM:\nMetodo dove ogni processo viene caricato in un'unica sezione di memoria contigua. La RAM è divisa in due parti: SO e processi utente. Il meccanismo è \"a partizioni multiple\". Quando un processo deve essere caricato, il SO cerca una porzione libera sufficientemente grande.\n\nCriteri di scelta:\n- Best-fit: la porzione più piccola tra quelle sufficienti\n- First-fit: la prima porzione sufficiente trovata\n- Worst-fit: la porzione più grande tra quelle libere\n\n(2) Vantaggi e svantaggi:\nVantaggi:\n- Semplicità di implementazione e gestione\n- Efficienza: accesso veloce alla memoria (dati contigui)\n\nSvantaggi:\n- Frammentazione esterna: memoria frammentata in piccoli buchi inutilizzabili\n- Limitata flessibilità: dimensione processo limitata dal buco più grande disponibile\n- Compattazione: necessaria per ridurre frammentazione, operazione costosa\n\nDistinzione frammentazione:\n- Esterna: parti libere non contigue, inutilizzabili per processi che richiedono spazio contiguo\n- Interna: parti molto piccole praticamente inutilizzabili",
      "maxPoints": 3,
      "negativePoints": 0,
      "type": "essay",
      "topics": [
        "memoria-primaria",
        "allocazione-memoria",
        "frammentazione"
      ]
    }
  ]
}